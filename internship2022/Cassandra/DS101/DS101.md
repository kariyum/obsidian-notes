# DS101
**ACID** => Atomicity, Consistency, Isolation and Durability.
**Durability**
	Ensures that the data will survive permanently, even in the case of system failures.
	
- Medium data : Data sets that are too large to fit on a single machine, hight **terbytes** but not **petabytes**.
- Cassandra prefers for **availability** rather than **consistency**
- Data is replicated automatically
- If a machine is down, missing data is replayed via hinted handoff.
- Predictable performance, as our cluster scales up we're not gonna have a single point failure.
- Peer to peer out of the box
- Extremely easy to manage numurous clusters
- Not the same data model as the relational database => design your application around cassandra modeling and rules so that the application will never go down.
- When you define your data model, we use partition key that will be used to determine which node that the data belongs (which bucket)
- All the of the data is replicated to all of the servers.
- There is no master / slave, all nodes are equal they can service any given read/write request.
- RF => Replication factor
- Data is always replicated in cassandra, you set this RF when you configure a key space which is a collection of tables similiar to a schema in SQL databases.
- This replication happens asynchronously and if a machine is down while this replication is supposed to go on, whatever node you happen to be talking to saves a hint and cassandra uses something called hinted handoffs to be able to replay when that node comes back up and rejoins the cluster.
- CL => Consistency Level
	- **Read**, how many node has to respond to the query in order for cassandra to fulfill the request.
	- **Write**, how many nodes have to react to updates (changes).
- Data is replicated asynchronously throughout data centers.
- Replication factor per key space per datacenter
- Data centers can be physical or logical.
- If you run cassandra with spark you can have one data center serving you with high speeds... *missing information*
#### CAP Tradeoffs
![[cap.png|400]]
- Impossible to be consistent and highly available during a network partition.
- Cassandra chooses to be highly available for the cost of consistency.

***
### Lession 3 : How cassandra read / writes work
**The Write Path**
- Any node can service the request that you send in.
- The node that you're talking to is called **coordinator node** it will sync the changes with other nodes. => coordinator node are specific to every query.
- Write request
	- Writes to the **commit log** that is append only data structure and that is specific to the node. => sequential I/O very fast => Durability acquired.
	- Merges that mutation up into in memory representation in your table
	- Repond back to the coordinator : "Yep, we wrote your data." .
	- Every write includes a timestamp
	- Writes to the memtable first and then flushed in SSTable
- SSTable immutable data strucutre.
- SSTable is then flushed into disk
- Compaction is then performed that will keep the newer data and disregards other lines. (which is the same data but updated --*as fast as i could understand*)
- This makes the writes very fast.

**Delete data**
- Cassandra writes a special kind of record name **tombstone** that is just a marker that says there is no data here as of this timestamp. => There is no data for this colomn anymore.

**Reads
- Coordinated.
- Look for many sstables in disk
- Once it pulls data : that could be in my sstables since probably the compaction did not occur yet.
- If there is unmerged data in the memtale, that gets merged and then actually sends a response to the coordinator / client.
- Serious impact that depends on the physical type of the disk if you have ready heavy work.
- **What if nodes disagree of the information** read repair occurs. (sync data)
- 